# WebLLM æœ¬åœ° AI ç”Ÿå›¾åŠ©æ‰‹ - å®æ–½è®¡åˆ’

## é¡¹ç›®æ¦‚è¿°

ä¸º CorineGen åº”ç”¨æ·»åŠ åŸºäº WebLLM çš„æœ¬åœ° AI åŠ©æ‰‹åŠŸèƒ½ï¼Œç”¨äºä¼˜åŒ–å’Œç”Ÿæˆ Stable Diffusion æç¤ºè¯ã€‚

---

## ä¸€ã€é¡¹ç›®åˆ†æç»“æœ

### 1.1 æŠ€æœ¯æ ˆ
| é¡¹ç›® | æŠ€æœ¯ |
|------|------|
| æ¡†æ¶ | React 18.2.0 |
| æ„å»º | Vite 5.0.8 |
| æ ·å¼ | åŸç”Ÿ CSS + CSS å˜é‡ï¼ˆæ—  Tailwindï¼‰ |
| çŠ¶æ€ | React Hooks (useState/useRef) |
| æŒä¹…åŒ– | LocalStorage |

### 1.2 å½“å‰ç»“æ„
```
CorineGen/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.jsx          # ä¸»åº”ç”¨ç»„ä»¶ï¼ˆ1877è¡Œï¼Œå•æ–‡ä»¶æ¶æ„ï¼‰
â”‚   â”œâ”€â”€ App.css          # å…¨å±€æ ·å¼
â”‚   â”œâ”€â”€ main.jsx         # å…¥å£
â”‚   â””â”€â”€ index.css        # CSSå˜é‡å®šä¹‰
â”œâ”€â”€ vite.config.js
â””â”€â”€ package.json
```

### 1.3 å…³é”®å‘ç°
- **è¾“å…¥æ¡†ä½ç½®**: `App.jsx` L1372-1442ï¼Œä½¿ç”¨ `<textarea>` + `.textarea-wrapper` å®¹å™¨
- **è®¾ç½®åŒºåŸŸ**: `App.jsx` L1455-1698 çš„ `<details className="advanced-settings">`
- **LocalStorage æ¨¡å¼**: `loadFromStorage()` å‡½æ•° + `useEffect` è‡ªåŠ¨ä¿å­˜
- **CSS å˜é‡ç³»ç»Ÿ**: æ”¯æŒåŠ¨æ€ä¸»é¢˜ (`--theme-hue`, `--theme-primary` ç­‰)

---

## äºŒã€æ¨¡å—åŒ–æ¶æ„è®¾è®¡

### 2.1 ç›®å½•ç»“æ„
```
src/
â””â”€â”€ modules/
    â””â”€â”€ ai-assistant/
        â”œâ”€â”€ constants.js        # é…ç½®å¸¸é‡
        â”œâ”€â”€ types.js            # ç±»å‹å®šä¹‰ï¼ˆJSDocï¼‰
        â”œâ”€â”€ useLocalModel.js    # WebLLM Hook
        â””â”€â”€ AIPromptOverlay.jsx # UI ç»„ä»¶
```

### 2.2 æ–‡ä»¶èŒè´£

#### `constants.js`
```javascript
// HuggingFace é•œåƒé…ç½®
export const HF_MIRROR_BASE = 'https://hf-mirror.com';
export const MODEL_ID = 'Qwen2-0.5B-Instruct-q4f16_1-MLC';
export const MODEL_URL = `${HF_MIRROR_BASE}/mlc-ai/${MODEL_ID}/resolve/main/`;
export const MODEL_LIB_URL = 'https://raw.githubusercontent.com/mlc-ai/binary-mlc-llm-libs/main/web-llm-models/v0.2.48/Qwen2-0.5B-Instruct-q4f16_1-MLC-webgpu.wasm';

// System Prompts
export const SYSTEM_PROMPTS = {
  optimize: `You are a Stable Diffusion prompt expert...`,
  variant: `You are a creative prompt engineer...`
};

// LocalStorage é”®
export const STORAGE_KEY = 'corineGen_aiAssistantEnabled';
```

#### `types.js`
```javascript
/**
 * @typedef {'optimize' | 'variant'} ActionType
 * @typedef {'idle' | 'downloading' | 'ready' | 'generating'} ModelStatus
 * @typedef {{
 *   status: ModelStatus,
 *   progress: number,
 *   error: string | null,
 *   preload: () => Promise<void>,
 *   generate: (prompt: string, action: ActionType) => Promise<string>
 * }} UseLocalModelReturn
 */
```

#### `useLocalModel.js`
- å°è£… `@mlc-ai/web-llm` çš„ `MLCEngineInterface`
- çŠ¶æ€æœºç®¡ç†ï¼š`idle` â†’ `downloading` (0-100%) â†’ `ready` â†’ `generating`
- æ³¨å…¥ `AppConfig` å¼ºåˆ¶ä½¿ç”¨ hf-mirror
- æš´éœ² `preload()` å’Œ `generate()` æ–¹æ³•

#### `AIPromptOverlay.jsx`
- æ— çŠ¶æ€ UI ç»„ä»¶
- Props: `status`, `progress`, `onOptimize`, `onVariant`, `disabled`
- åŒ…å« Split Buttonï¼ˆä¸»æŒ‰é’® + ä¸‹æ‹‰èœå•ï¼‰

---

## ä¸‰ã€é›†æˆæ–¹æ¡ˆ

### 3.1 è®¾ç½®é¡µé¢é›†æˆ

**ä½ç½®**: `App.jsx` é«˜çº§è®¾ç½®åŒºåŸŸ

**æ–°å¢å†…å®¹**:
```jsx
{/* AI åŠ©æ‰‹å¼€å…³ - æ’å…¥åˆ°é«˜çº§è®¾ç½®é¡¶éƒ¨ */}
<div className="setting-group ai-assistant-setting">
  <label className="checkbox-label">
    <input
      type="checkbox"
      checked={aiAssistantEnabled}
      onChange={handleAIToggle}
    />
    <span>AI åŠ©æ‰‹ (Beta)</span>
  </label>
  {aiAssistantEnabled && (
    <div className="ai-status">
      {/* çŠ¶æ€æŒ‡ç¤ºå™¨ï¼šä¸‹è½½è¿›åº¦ / å·²å°±ç»ª */}
    </div>
  )}
</div>
```

**äº¤äº’æµç¨‹**:
1. ç”¨æˆ·ç‚¹å‡»å¼€å¯ â†’ æ˜¾ç¤ºç¡®è®¤å¼¹çª— ("éœ€ä¸‹è½½çº¦ 350MB æ¨¡å‹")
2. ç¡®è®¤å â†’ è°ƒç”¨ `useLocalModel().preload()`
3. æ˜¾ç¤ºä¸‹è½½è¿›åº¦æ¡ â†’ å®Œæˆåä¿å­˜åˆ° LocalStorage

### 3.2 è¾“å…¥æ¡†é›†æˆ

**ä½ç½®**: `App.jsx` çš„ `.textarea-wrapper` å†…éƒ¨

**ä¿®æ”¹æ–¹æ¡ˆ**:
```jsx
<div className="textarea-wrapper">
  <textarea ... />

  {/* æ–°å¢ï¼šAI åŠ©æ‰‹æ‚¬æµ®æŒ‰é’® */}
  {aiAssistantEnabled && (
    <AIPromptOverlay
      status={modelStatus}
      progress={modelProgress}
      onOptimize={() => handleAIAction('optimize', promptItem.id)}
      onVariant={() => handleAIAction('variant', promptItem.id)}
      disabled={isGenerating}
    />
  )}

  {/* ç°æœ‰æŒ‰é’®ä¿æŒä¸å˜ */}
  <button className="delete-prompt-button">Ã—</button>
  <button className="paste-prompt-button">ğŸ“‹</button>
  <button className="send-button">â†’</button>
</div>
```

**CSS å¸ƒå±€**:
```css
.ai-assistant-overlay {
  position: absolute;
  top: 8px;
  right: 8px;
  z-index: 10;
}
```

### 3.3 çŠ¶æ€ç®¡ç†

**æ–°å¢ State**:
```javascript
// AI åŠ©æ‰‹çŠ¶æ€
const [aiAssistantEnabled, setAIAssistantEnabled] = useState(() =>
  loadFromStorage('corineGen_aiAssistantEnabled', false)
);

// useLocalModel Hook æä¾›çš„çŠ¶æ€é€šè¿‡ context æˆ–ç›´æ¥ä½¿ç”¨
```

---

## å››ã€Vercel éƒ¨ç½²é…ç½®

**æ–°å»ºæ–‡ä»¶**: `vercel.json`

```json
{
  "headers": [
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "Cross-Origin-Opener-Policy",
          "value": "same-origin"
        },
        {
          "key": "Cross-Origin-Embedder-Policy",
          "value": "require-corp"
        }
      ]
    }
  ]
}
```

**è¯´æ˜**: è¿™äº› Headers æ˜¯ SharedArrayBuffer æ‰€éœ€çš„ï¼ŒWebLLM/WebGPU éœ€è¦æ­¤åŠŸèƒ½ã€‚

---

## äº”ã€å®æ–½æ­¥éª¤

### Phase 1: åŸºç¡€è®¾æ–½
- [ ] å®‰è£…ä¾èµ– `@mlc-ai/web-llm`
- [ ] åˆ›å»º `src/modules/ai-assistant/` ç›®å½•
- [ ] ç¼–å†™ `constants.js`
- [ ] ç¼–å†™ `types.js`

### Phase 2: æ ¸å¿ƒ Hook
- [ ] ç¼–å†™ `useLocalModel.js`
- [ ] å®ç°çŠ¶æ€æœºé€»è¾‘
- [ ] é…ç½® hf-mirror é•œåƒ
- [ ] æ·»åŠ é”™è¯¯å¤„ç†

### Phase 3: UI ç»„ä»¶
- [ ] ç¼–å†™ `AIPromptOverlay.jsx`
- [ ] æ·»åŠ å¯¹åº” CSS æ ·å¼åˆ° `App.css`
- [ ] å®ç° Split Button äº¤äº’

### Phase 4: é›†æˆ
- [ ] ä¿®æ”¹ `App.jsx` æ·»åŠ è®¾ç½®å¼€å…³
- [ ] åœ¨è¾“å…¥æ¡†åŒºåŸŸé›†æˆ Overlay
- [ ] å®ç°ç¡®è®¤å¼¹çª—
- [ ] å¤„ç†ç”Ÿæˆç»“æœå›å¡«

### Phase 5: éƒ¨ç½²é…ç½®
- [ ] åˆ›å»º `vercel.json`
- [ ] æœ¬åœ°æµ‹è¯• CORS Headers

---

## å…­ã€å…³é”®æ–‡ä»¶æ¸…å•

| æ“ä½œ | æ–‡ä»¶è·¯å¾„ |
|------|----------|
| æ–°å»º | `src/modules/ai-assistant/constants.js` |
| æ–°å»º | `src/modules/ai-assistant/types.js` |
| æ–°å»º | `src/modules/ai-assistant/useLocalModel.js` |
| æ–°å»º | `src/modules/ai-assistant/AIPromptOverlay.jsx` |
| æ–°å»º | `vercel.json` |
| ä¿®æ”¹ | `src/App.jsx` |
| ä¿®æ”¹ | `src/App.css` |
| ä¿®æ”¹ | `package.json` (æ·»åŠ ä¾èµ–) |

---

## ä¸ƒã€éªŒè¯æ–¹æ¡ˆ

1. **å•å…ƒæµ‹è¯•**: éªŒè¯ `useLocalModel` çŠ¶æ€æœºè½¬æ¢
2. **é›†æˆæµ‹è¯•**:
   - å¼€å¯ AI åŠ©æ‰‹ â†’ éªŒè¯ä¸‹è½½è¿›åº¦æ˜¾ç¤º
   - è¾“å…¥æç¤ºè¯ â†’ ç‚¹å‡»ä¼˜åŒ– â†’ éªŒè¯ç»“æœå›å¡«
   - æµ‹è¯•å˜ä½“æ¨¡å¼
3. **éƒ¨ç½²æµ‹è¯•**:
   - éªŒè¯ Vercel ä¸Š CORS Headers æ­£ç¡®
   - éªŒè¯ hf-mirror æ¨¡å‹ä¸‹è½½æˆåŠŸ

---

## å…«ã€æ³¨æ„äº‹é¡¹

1. **ç½‘ç»œé—®é¢˜**: GitHub Raw å¯èƒ½åœ¨å›½å†…ä¸å¯è¾¾ï¼ŒWASM æ–‡ä»¶å¯èƒ½éœ€è¦æ‰‹åŠ¨ä¸‹è½½
2. **æµè§ˆå™¨å…¼å®¹**: WebGPU éœ€è¦ Chrome 113+ / Edge 113+
3. **é¦–æ¬¡åŠ è½½**: 350MB æ¨¡å‹ä¸‹è½½éœ€è¦æ—¶é—´ï¼Œéœ€æä¾›è‰¯å¥½çš„è¿›åº¦åé¦ˆ
4. **å†…å­˜å ç”¨**: Qwen2-0.5B æ¨¡å‹çº¦å ç”¨ 500MB æ˜¾å­˜
